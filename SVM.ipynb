{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cb4acb-3f90-4611-a426-966cd5d48650",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "В программе ниже сформирована обучающая выборка для задачи бинарной классификации.\n",
    "\n",
    "Продолжите эту программу. С помощью алгоритма SVM (Support Vector Machine) с линейным ядром вычислите коэффициенты:\n",
    "\n",
    "$w = [w_0, w_1, w_2]^T $\n",
    "\n",
    "параметрической модели:\n",
    "\n",
    "$a(x) = sign(w^T * x) $\n",
    "\n",
    "или, что то же самое, коэффициентов разделяющей гиперплоскости:\n",
    "\n",
    "$w_0 + w_1*x_1 + w_2*x_2 = 0$ (1)\n",
    "\n",
    "Воспользуйтесь для этого классом svm.LinearSVC пакета Scikit-Learn с аргументами по умолчанию. Значения коэффициентов w можно получить через атрибут coef_[0] объекта класса svm.LinearSVC. Чтобы они соответствовали уравнению (1) коэффициент $w_0$ следует умножить на коэффициент $w_2$.\n",
    "\n",
    "Вычислите количество неверных классификаций в обучающей выборке по формуле:\n",
    "\n",
    "$$Q(a,X) = \\sum_ {i=1}^n [a(x_i) \\not = y_i] =  \\sum_ {i=1}^n [sign(w^T*x_i) \\not = y_i]$$\n",
    "\n",
    "Сохраните вектор коэффициентов w в переменной ``w``, а значение величины Q(a,X) в переменной ``Q``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bbf74b-9896-4bf5-a665-047f1bd4e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "data_x = [(4.9, 3.3), (5.6, 4.5), (6.4, 4.3), (6.7, 5.7), (6.3, 5.0), (5.2, 3.9), (5.5, 3.7), (5.6, 3.6), (5.5, 3.8), (6.1, 4.7), (7.4, 6.1), (6.0, 5.1), (5.5, 4.4), (5.9, 5.1), (6.5, 5.8), (6.5, 4.6), (6.7, 4.4), (6.3, 5.6), (5.9, 4.8), (6.0, 4.5), (5.6, 4.1), (5.6, 4.9), (4.9, 4.5), (6.2, 4.5), (6.1, 4.7), (6.1, 4.9), (6.2, 5.4), (5.7, 4.2), (6.1, 5.6), (5.8, 4.0), (6.6, 4.6), (5.6, 4.2), (7.2, 6.1), (7.7, 6.7), (5.6, 3.9), (7.7, 6.9), (6.0, 4.0), (6.1, 4.0), (7.6, 6.6), (5.1, 3.0), (6.3, 6.0), (6.7, 5.7), (6.8, 5.9), (6.4, 5.5), (7.0, 4.7), (5.8, 5.1), (5.8, 5.1), (6.4, 5.3), (6.3, 4.9), (6.4, 5.3), (5.7, 3.5), (7.2, 5.8), (6.4, 5.6), (5.7, 4.5), (6.0, 4.5), (7.7, 6.1), (6.2, 4.3), (7.1, 5.9), (7.3, 6.3), (5.0, 3.3), (6.3, 5.1), (5.8, 3.9), (6.4, 4.5), (6.3, 5.6), (6.8, 5.5), (6.9, 5.4), (5.5, 4.0), (5.7, 4.1), (6.5, 5.5), (6.3, 4.7), (5.0, 3.5), (6.7, 5.8), (6.9, 4.9), (7.7, 6.7), (5.8, 4.1), (6.4, 5.6), (6.7, 5.2), (6.7, 4.7), (5.4, 4.5), (6.8, 4.8), (5.7, 4.2), (5.5, 4.0), (6.3, 4.9), (6.5, 5.2), (5.8, 5.1), (6.0, 4.8), (6.2, 4.8), (6.5, 5.1), (7.9, 6.4), (6.7, 5.0), (6.7, 5.6), (6.0, 5.0), (6.1, 4.6), (5.7, 5.0), (7.2, 6.0), (6.3, 4.4), (5.9, 4.2), (6.9, 5.1), (6.6, 4.4), (6.9, 5.7)]\n",
    "data_y = [-1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1]\n",
    "\n",
    "# обучающая выборка в формате [1, x1, x2]\n",
    "x_train = np.array([[1] + list(x) for x in data_x]) # входные образы\n",
    "y_train = np.array(data_y) # целевые значения (метки классов)\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.coef_[0][0] *= clf.coef_[0][2]\n",
    "w = clf.coef_[0]\n",
    "\n",
    "Q = sum(y_train != np.sign(np.dot(w, x_train.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f87f74-cb51-4a6d-89df-800ab7e4d0da",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "\n",
    "В программе ниже сформирована обучающая выборка для задачи бинарной классификации\n",
    "\n",
    "Продолжите эту программу. С помощью алгоритма SVM (Support Vector Machine) с линейным ядром вычислите коэффициенты:\n",
    "\n",
    "$w = [w_0, w_1, w_2]^T $\n",
    "\n",
    "коэффициентов разделяющей гиперплоскости:\n",
    "\n",
    "$w_0 + w_1*x_1 + w_2*x_2 = 0$ \n",
    "\n",
    "Воспользуйтесь для этого классом svm.SVC пакета Scikit-Learn следующим образом:\n",
    "\n",
    "``clf = svm.SVC(kernel='linear')    # SVM с линейным ядром``\n",
    "\n",
    "Затем, используя объект clf, с помощью метода fit вычислите коэффициенты w по выборке data_x, data_y (а не x_train, y_train).\n",
    "\n",
    "Значения вычисленных коэффициентов $w_{12} = [w_1, w_2]^T $ можно получить через атрибут _coeff объекта clf:\n",
    "\n",
    "``w12 = clf.coef_[0] # коэффициенты w1, w2 разделяющей гиперплоскости``\n",
    "\n",
    "А величину смещения (коэффициент $w_0$) - через атрибут intercept_:\n",
    "\n",
    "``w0 = clf.intercept_[0] # коэффициент w0 разделяющей гиперплоскости``\n",
    "\n",
    "Также объект clf позволяет получить список опорных векторов с помощью атрибута support_vectors_ следующей командой:\n",
    "\n",
    "``v_support = clf.support_vectors_ # список опорных векторов``\n",
    "\n",
    "Вычислите количество неверных классификаций в обучающей выборке по формуле:\n",
    "\n",
    "$$Q(a,X) = \\sum_ {i=1}^n [a(x_i) \\not = y_i] =  \\sum_ {i=1}^n [sign(w^T*x_i) \\not = y_i]$$\n",
    "\n",
    "где $w = [w_0, w_1, w_2]^T$; $x_i^T = [1,x_1,x_2]^T$ - вектор признаков i-го образа; $y_i$ - метка i-го класса.\n",
    "\n",
    "Сохраните вектор коэффициентов w в переменной ``w``, опорные векторы в списке ``v_support``, а значение величины Q(a,X) в переменной ``Q``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd268f3b-7090-4437-835c-8af2468892a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "data_x = [(3.0, 4.9), (2.7, 3.9), (3.0, 5.5), (2.6, 4.0), (2.9, 4.3), (3.1, 5.1), (2.2, 4.5), (2.3, 3.3), (2.7, 5.1), (3.3, 5.7), (2.8, 5.1), (2.8, 4.9), (2.5, 4.5), (2.8, 4.7), (3.2, 4.7), (3.2, 5.7), (2.8, 6.1), (3.6, 6.1), (2.8, 4.8), (2.9, 4.5), (3.1, 4.9), (2.3, 4.4), (3.3, 6.0), (2.6, 5.6), (3.0, 4.4), (2.9, 4.7), (2.8, 4.0), (2.5, 5.8), (2.4, 3.3), (2.8, 6.7), (3.0, 5.1), (2.3, 4.0), (3.1, 5.5), (2.8, 4.8), (2.7, 5.1), (2.5, 4.0), (3.1, 4.4), (3.8, 6.7), (3.1, 5.6), (3.1, 4.7), (3.0, 5.8), (3.0, 5.2), (3.0, 4.5), (2.7, 4.9), (3.0, 6.6), (2.9, 4.6), (3.0, 4.6), (2.6, 3.5), (2.7, 5.1), (2.5, 5.0), (2.0, 3.5), (3.2, 5.9), (2.5, 5.0), (3.4, 5.6), (3.4, 4.5), (3.2, 5.3), (2.2, 4.0), (2.2, 5.0), (3.3, 4.7), (2.7, 4.1), (2.4, 3.7), (3.0, 4.2), (3.2, 6.0), (3.0, 4.2), (3.0, 4.5), (2.7, 4.2), (2.5, 3.0), (2.8, 4.6), (2.9, 4.2), (3.1, 5.4), (2.5, 4.9), (3.2, 5.1), (2.8, 4.5), (2.8, 5.6), (3.4, 5.4), (2.7, 3.9), (3.0, 6.1), (3.0, 5.8), (3.0, 4.1), (2.5, 3.9), (2.4, 3.8), (2.6, 4.4), (2.9, 3.6), (3.3, 5.7), (2.9, 5.6), (3.0, 5.2), (3.0, 4.8), (2.7, 5.3), (2.8, 4.1), (2.8, 5.6), (3.2, 4.5), (3.0, 5.9), (2.9, 4.3), (2.6, 6.9), (2.8, 5.1), (2.9, 6.3), (3.2, 4.8), (3.0, 5.5), (3.0, 5.0), (3.8, 6.4)]\n",
    "data_y = [1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1]\n",
    "\n",
    "# обучающая выборка в формате [1, x1, x2]\n",
    "x_train = np.array([[1] + list(x) for x in data_x]) # входные образы\n",
    "y_train = np.array(data_y) # целевые значения (метки классов)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "w12 = clf.coef_[0]\n",
    "w0 = clf.intercept_[0]\n",
    "\n",
    "w = np.array([w0, w12[0], w12[1]])\n",
    "\n",
    "v_support = clf.support_vectors_\n",
    "\n",
    "Q = sum(y_train != np.sign(np.dot(w, x_train.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb3695-ea88-488f-8a2d-ab34570490c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f550cc8b-a9b9-4700-964d-f29a6b607bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "def func(x):\n",
    "    return np.sin(0.5*x) + 0.2 * np.cos(2*x) - 0.1 * np.sin(4 * x) - 2.5\n",
    "\n",
    "\n",
    "def model(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * x ** 2 + w[3] * x ** 3 + w[4] * np.cos(x) + w[5] * np.sin(x)\n",
    "\n",
    "# обучающая выборка\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "coord_y = func(coord_x)\n",
    "\n",
    "x_train = np.array([[x, x**2, x**3, np.cos(x), np.sin(x)] for x in coord_x])\n",
    "y_train = coord_y\n",
    "\n",
    "svr = svm.SVR(kernel='linear')\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "wn = svr.coef_[0]\n",
    "w0 = svr.intercept_[0]\n",
    "w = np.hstack((w0, wn))\n",
    "\n",
    "Q = np.mean((model(w, coord_x) - y_train)**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
