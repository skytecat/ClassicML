{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cb4acb-3f90-4611-a426-966cd5d48650",
   "metadata": {},
   "source": [
    "## Задание №1\n",
    "\n",
    "В программе ниже сформирована обучающая выборка для задачи бинарной классификации.\n",
    "\n",
    "Продолжите эту программу. С помощью алгоритма SVM (Support Vector Machine) с линейным ядром вычислите коэффициенты:\n",
    "\n",
    "$w = [w_0, w_1, w_2]^T $\n",
    "\n",
    "параметрической модели:\n",
    "\n",
    "$a(x) = sign(w^T * x) $\n",
    "\n",
    "или, что то же самое, коэффициентов разделяющей гиперплоскости:\n",
    "\n",
    "$w_0 + w_1*x_1 + w_2*x_2 = 0$ (1)\n",
    "\n",
    "Воспользуйтесь для этого классом svm.LinearSVC пакета Scikit-Learn с аргументами по умолчанию. Значения коэффициентов w можно получить через атрибут coef_[0] объекта класса svm.LinearSVC. Чтобы они соответствовали уравнению (1) коэффициент $w_0$ следует умножить на коэффициент $w_2$.\n",
    "\n",
    "Вычислите количество неверных классификаций в обучающей выборке по формуле:\n",
    "\n",
    "$$Q(a,X) = \\sum_ {i=1}^n [a(x_i) \\not = y_i] =  \\sum_ {i=1}^n [sign(w^T*x_i) \\not = y_i]$$\n",
    "\n",
    "Сохраните вектор коэффициентов w в переменной ``w``, а значение величины Q(a,X) в переменной ``Q``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bbf74b-9896-4bf5-a665-047f1bd4e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "data_x = [(4.9, 3.3), (5.6, 4.5), (6.4, 4.3), (6.7, 5.7), (6.3, 5.0), (5.2, 3.9), (5.5, 3.7), (5.6, 3.6), (5.5, 3.8), (6.1, 4.7), (7.4, 6.1), (6.0, 5.1), (5.5, 4.4), (5.9, 5.1), (6.5, 5.8), (6.5, 4.6), (6.7, 4.4), (6.3, 5.6), (5.9, 4.8), (6.0, 4.5), (5.6, 4.1), (5.6, 4.9), (4.9, 4.5), (6.2, 4.5), (6.1, 4.7), (6.1, 4.9), (6.2, 5.4), (5.7, 4.2), (6.1, 5.6), (5.8, 4.0), (6.6, 4.6), (5.6, 4.2), (7.2, 6.1), (7.7, 6.7), (5.6, 3.9), (7.7, 6.9), (6.0, 4.0), (6.1, 4.0), (7.6, 6.6), (5.1, 3.0), (6.3, 6.0), (6.7, 5.7), (6.8, 5.9), (6.4, 5.5), (7.0, 4.7), (5.8, 5.1), (5.8, 5.1), (6.4, 5.3), (6.3, 4.9), (6.4, 5.3), (5.7, 3.5), (7.2, 5.8), (6.4, 5.6), (5.7, 4.5), (6.0, 4.5), (7.7, 6.1), (6.2, 4.3), (7.1, 5.9), (7.3, 6.3), (5.0, 3.3), (6.3, 5.1), (5.8, 3.9), (6.4, 4.5), (6.3, 5.6), (6.8, 5.5), (6.9, 5.4), (5.5, 4.0), (5.7, 4.1), (6.5, 5.5), (6.3, 4.7), (5.0, 3.5), (6.7, 5.8), (6.9, 4.9), (7.7, 6.7), (5.8, 4.1), (6.4, 5.6), (6.7, 5.2), (6.7, 4.7), (5.4, 4.5), (6.8, 4.8), (5.7, 4.2), (5.5, 4.0), (6.3, 4.9), (6.5, 5.2), (5.8, 5.1), (6.0, 4.8), (6.2, 4.8), (6.5, 5.1), (7.9, 6.4), (6.7, 5.0), (6.7, 5.6), (6.0, 5.0), (6.1, 4.6), (5.7, 5.0), (7.2, 6.0), (6.3, 4.4), (5.9, 4.2), (6.9, 5.1), (6.6, 4.4), (6.9, 5.7)]\n",
    "data_y = [-1, -1, -1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, -1, 1]\n",
    "\n",
    "# обучающая выборка в формате [1, x1, x2]\n",
    "x_train = np.array([[1] + list(x) for x in data_x]) # входные образы\n",
    "y_train = np.array(data_y) # целевые значения (метки классов)\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.coef_[0][0] *= clf.coef_[0][2]\n",
    "w = clf.coef_[0]\n",
    "\n",
    "Q = sum(y_train != np.sign(np.dot(w, x_train.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f87f74-cb51-4a6d-89df-800ab7e4d0da",
   "metadata": {},
   "source": [
    "## Задание №2\n",
    "\n",
    "В программе ниже сформирована обучающая выборка для задачи бинарной классификации\n",
    "\n",
    "Продолжите эту программу. С помощью алгоритма SVM (Support Vector Machine) с линейным ядром вычислите коэффициенты:\n",
    "\n",
    "$w = [w_0, w_1, w_2]^T $\n",
    "\n",
    "коэффициентов разделяющей гиперплоскости:\n",
    "\n",
    "$w_0 + w_1*x_1 + w_2*x_2 = 0$ \n",
    "\n",
    "Воспользуйтесь для этого классом svm.SVC пакета Scikit-Learn следующим образом:\n",
    "\n",
    "``clf = svm.SVC(kernel='linear')    # SVM с линейным ядром``\n",
    "\n",
    "Затем, используя объект clf, с помощью метода fit вычислите коэффициенты w по выборке data_x, data_y (а не x_train, y_train).\n",
    "\n",
    "Значения вычисленных коэффициентов $w_{12} = [w_1, w_2]^T $ можно получить через атрибут _coeff объекта clf:\n",
    "\n",
    "``w12 = clf.coef_[0] # коэффициенты w1, w2 разделяющей гиперплоскости``\n",
    "\n",
    "А величину смещения (коэффициент $w_0$) - через атрибут intercept_:\n",
    "\n",
    "``w0 = clf.intercept_[0] # коэффициент w0 разделяющей гиперплоскости``\n",
    "\n",
    "Также объект clf позволяет получить список опорных векторов с помощью атрибута support_vectors_ следующей командой:\n",
    "\n",
    "``v_support = clf.support_vectors_ # список опорных векторов``\n",
    "\n",
    "Вычислите количество неверных классификаций в обучающей выборке по формуле:\n",
    "\n",
    "$$Q(a,X) = \\sum_ {i=1}^n [a(x_i) \\not = y_i] =  \\sum_ {i=1}^n [sign(w^T*x_i) \\not = y_i]$$\n",
    "\n",
    "где $w = [w_0, w_1, w_2]^T$; $x_i^T = [1,x_1,x_2]^T$ - вектор признаков i-го образа; $y_i$ - метка i-го класса.\n",
    "\n",
    "Сохраните вектор коэффициентов w в переменной ``w``, опорные векторы в списке ``v_support``, а значение величины Q(a,X) в переменной ``Q``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd268f3b-7090-4437-835c-8af2468892a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "data_x = [(3.0, 4.9), (2.7, 3.9), (3.0, 5.5), (2.6, 4.0), (2.9, 4.3), (3.1, 5.1), (2.2, 4.5), (2.3, 3.3), (2.7, 5.1), (3.3, 5.7), (2.8, 5.1), (2.8, 4.9), (2.5, 4.5), (2.8, 4.7), (3.2, 4.7), (3.2, 5.7), (2.8, 6.1), (3.6, 6.1), (2.8, 4.8), (2.9, 4.5), (3.1, 4.9), (2.3, 4.4), (3.3, 6.0), (2.6, 5.6), (3.0, 4.4), (2.9, 4.7), (2.8, 4.0), (2.5, 5.8), (2.4, 3.3), (2.8, 6.7), (3.0, 5.1), (2.3, 4.0), (3.1, 5.5), (2.8, 4.8), (2.7, 5.1), (2.5, 4.0), (3.1, 4.4), (3.8, 6.7), (3.1, 5.6), (3.1, 4.7), (3.0, 5.8), (3.0, 5.2), (3.0, 4.5), (2.7, 4.9), (3.0, 6.6), (2.9, 4.6), (3.0, 4.6), (2.6, 3.5), (2.7, 5.1), (2.5, 5.0), (2.0, 3.5), (3.2, 5.9), (2.5, 5.0), (3.4, 5.6), (3.4, 4.5), (3.2, 5.3), (2.2, 4.0), (2.2, 5.0), (3.3, 4.7), (2.7, 4.1), (2.4, 3.7), (3.0, 4.2), (3.2, 6.0), (3.0, 4.2), (3.0, 4.5), (2.7, 4.2), (2.5, 3.0), (2.8, 4.6), (2.9, 4.2), (3.1, 5.4), (2.5, 4.9), (3.2, 5.1), (2.8, 4.5), (2.8, 5.6), (3.4, 5.4), (2.7, 3.9), (3.0, 6.1), (3.0, 5.8), (3.0, 4.1), (2.5, 3.9), (2.4, 3.8), (2.6, 4.4), (2.9, 3.6), (3.3, 5.7), (2.9, 5.6), (3.0, 5.2), (3.0, 4.8), (2.7, 5.3), (2.8, 4.1), (2.8, 5.6), (3.2, 4.5), (3.0, 5.9), (2.9, 4.3), (2.6, 6.9), (2.8, 5.1), (2.9, 6.3), (3.2, 4.8), (3.0, 5.5), (3.0, 5.0), (3.8, 6.4)]\n",
    "data_y = [1, -1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, -1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1]\n",
    "\n",
    "# обучающая выборка в формате [1, x1, x2]\n",
    "x_train = np.array([[1] + list(x) for x in data_x]) # входные образы\n",
    "y_train = np.array(data_y) # целевые значения (метки классов)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(data_x, data_y)\n",
    "\n",
    "w12 = clf.coef_[0]\n",
    "w0 = clf.intercept_[0]\n",
    "\n",
    "w = np.array([w0, w12[0], w12[1]])\n",
    "\n",
    "v_support = clf.support_vectors_\n",
    "\n",
    "Q = sum(y_train != np.sign(np.dot(w, x_train.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7db41b-fcc7-43cf-9601-60a811ef4e08",
   "metadata": {},
   "source": [
    "## Задание №3\n",
    "\n",
    "С помощью метода опорных векторов можно решать и задачи регрессии. В этом случае имеем дело с SVR (Support Vector Regression), когда выходные значения представляют собой вещественные числа, а не метки классов. \n",
    "\n",
    "Давайте представим, что нам необходимо аппроксимировать функцию:\n",
    "\n",
    "$f(x) = sin(x/2) + 0.2*cos(2x) - 0.1*sin(4x) - 2.5 $\n",
    "\n",
    "линейной моделью вида:\n",
    "\n",
    "$a(x) = w_0 + w_1*x + w_2*x^2 + w_3*x^3 + w_4*cos(x) + w_5*sin(x) $\n",
    "\n",
    "То есть, вектор признаков $x_i$ будет состоять из следующих компонент:\n",
    "\n",
    "$x_i = [1,x,x^2,x^3,cos(x),sin(x)]^T $\n",
    "\n",
    "Алгоритм SVR выполняет поиск вектора параметров $w^T = [w_0,w_1,w_2,w_3,w_4,w_5]^T $ по тому же алгоритму, что и SVM (который используется для задачи классификации), но с небольшим отличием. Функция потерь в SVR записывается в виде:\n",
    "\n",
    "$L_i(w) = ∣a(x_i) - y_i∣_ϵ = max(0,∣a(x_i) - y_i∣ - ) $\n",
    "\n",
    "где ϵ>0 - величина отклонения от требуемых значений.\n",
    "\n",
    "В программе ниже объявлена функция f(x) с именем func, модель a(x) с именем model, а также сформирована обучающая выборка x_train, y_train\n",
    "\n",
    "Продолжите программу. С помощью алгоритма SVR с линейным ядром вычислите коэффициенты:\n",
    "\n",
    "$w = [w_0,w_1,w_2,w_3,w_4,w_5]^T $\n",
    "\n",
    "Воспользуйтесь для этого классом svm.SVR пакета Scikit-Learn следующим образом:\n",
    "\n",
    "``svr = svm.SVR(kernel='linear')    # SVR с линейным ядром``\n",
    "\n",
    "Затем, используя объект svr, с помощью метода fit вычислите коэффициенты w по выборке x_train, y_train. Значения вычисленных коэффициентов w можно получить через атрибут coeff_ объекта svr:\n",
    "\n",
    "``w1 = svr.coef_[0] # коэффициенты w1, w2, ...``\n",
    "\n",
    "А величину смещения (коэффициент $w_0$) - через атрибут intercept_:\n",
    "\n",
    "``w0 = svr.intercept_[0] # коэффициент w0``\n",
    "\n",
    "Вычислите качество восстановления исходной функции f(x) обученной моделью a(x) по формуле:\n",
    "\n",
    "$$Q(a,X) = \\frac{1}{n} \\sum_ {i=1}^n (a(x_i) - y_i)^2 $$\n",
    "\n",
    "Сохраните вектор коэффициентов w в переменной ``w``, а значение величины Q(a,X) в переменной ``Q``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f550cc8b-a9b9-4700-964d-f29a6b607bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "def func(x):\n",
    "    return np.sin(0.5*x) + 0.2 * np.cos(2*x) - 0.1 * np.sin(4 * x) - 2.5\n",
    "\n",
    "\n",
    "def model(w, x):\n",
    "    return w[0] + w[1] * x + w[2] * x ** 2 + w[3] * x ** 3 + w[4] * np.cos(x) + w[5] * np.sin(x)\n",
    "\n",
    "# обучающая выборка\n",
    "coord_x = np.arange(-4.0, 6.0, 0.1)\n",
    "coord_y = func(coord_x)\n",
    "\n",
    "x_train = np.array([[x, x**2, x**3, np.cos(x), np.sin(x)] for x in coord_x])\n",
    "y_train = coord_y\n",
    "\n",
    "svr = svm.SVR(kernel='linear')\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "wn = svr.coef_[0]\n",
    "w0 = svr.intercept_[0]\n",
    "w = np.hstack((w0, wn))\n",
    "\n",
    "Q = np.mean((model(w, coord_x) - y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759fe04c-df9c-4455-b95f-9a0cece83d9a",
   "metadata": {},
   "source": [
    "## Задание №4\n",
    "\n",
    "С помощью метода опорных векторов можно выполнять классификацию образов для множества классов, заданных метками \n",
    "Y={0,1,2,…}. На уровне пакета Scikit-Learn все выполняется по аналогии с бинарной классификацией.\n",
    "\n",
    "В программе ниже сформирована обучающая выборка (x_train, y_train) и тестовая (x_test, y_test), состоящая из образов трех классов с метками Y={0,1,2}\n",
    "\n",
    "Продолжите эту программу. С помощью алгоритма SVM (Support Vector Machine) с линейным ядром вычислите коэффициенты w для разделяющих гиперплоскостей. Для этого воспользуйтесь классом svm.SVC пакета Scikit-Learn следующим образом:\n",
    "\n",
    "``clf = svm.SVC(kernel='linear')    # SVM с линейным ядром``\n",
    "\n",
    "Затем, используя объект clf, с помощью метода fit вычислите коэффициенты w по выборке x_train, y_train.\n",
    "\n",
    "Значения вычисленных коэффициентов w можно получить через атрибут coeff_ объекта clf:\n",
    "\n",
    "``w1 = clf.coef_[0] # коэффициенты для 1-й разделяющей гиперплоскости``\n",
    "\n",
    "``w2 = clf.coef_[1] # коэффициенты для 2-й разделяющей гиперплоскости``\n",
    "\n",
    "``w3 = clf.coef_[2] # коэффициенты для 3-й разделяющей гиперплоскости``\n",
    "\n",
    "А величины смещений (коэффициенты $w_0$ ) - через атрибут intercept_:\n",
    "\n",
    "``w01 = clf.intercept_[0] # коэффициент w0 для 1-й гиперплоскости``\n",
    "\n",
    "``w02 = clf.intercept_[1] # коэффициент w0 для 2-й гиперплоскости``\n",
    "\n",
    "``w03 = clf.intercept_[2] # коэффициент w0 для 3-й гиперплоскости``\n",
    "\n",
    "Прогноз того или иного класса для образа $x_i = [x_1, x_2]^T $ выполняется по многоклассовой стратегии \"один против остальных\" (one-vs-rest). Поэтому прогнозы классов для выборки x_test следует делать с помощью метода predict объекта clf:\n",
    "\n",
    "``predict = clf.predict(x_test) # построение прогнозов меток классов для всей выборки``\n",
    "\n",
    "Вычислите количество неверных классификаций по тестовой выборке x_test, y_test по формуле:\n",
    "\n",
    "$$Q(a,X) = \\sum_ {i=1}^n [y_i \\not = predict_i] $$\n",
    "\n",
    "Сохраните векторы коэффициентов w1,w2,w3 для 1-й, 2-й, 3-й гиперплоскости соответственно в переменных ``w1``, ``w2``, ``w3``, а значение величины Q(a,X) в переменной ``Q``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8cd4c-6c1f-4015-a5ee-c62ec945232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "# исходные параметры распределений классов\n",
    "r1 = 0.6\n",
    "D1 = 3.0\n",
    "mean1 = [1, -2]\n",
    "V1 = [[D1, D1 * r1], [D1 * r1, D1]]\n",
    "\n",
    "r2 = 0.7\n",
    "D2 = 2.0\n",
    "mean2 = [-3, -1]\n",
    "V2 = [[D2, D2 * r2], [D2 * r2, D2]]\n",
    "\n",
    "r3 = 0.5\n",
    "D3 = 1.0\n",
    "mean3 = [1, 2]\n",
    "V3 = [[D3, D3 * r3], [D3 * r3, D3]]\n",
    "\n",
    "# моделирование обучающей выборки\n",
    "N = 500\n",
    "x1 = np.random.multivariate_normal(mean1, V1, N).T\n",
    "x2 = np.random.multivariate_normal(mean2, V2, N).T\n",
    "x3 = np.random.multivariate_normal(mean3, V3, N).T\n",
    "\n",
    "data_x = np.hstack([x1, x2, x3]).T\n",
    "data_y = np.hstack([np.zeros(N), np.ones(N), np.ones(N) * 2])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, random_state=123,test_size=0.3, shuffle=True)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "w1 = np.hstack((clf.intercept_[0], clf.coef_[0]))\n",
    "w2 = np.hstack((clf.intercept_[1], clf.coef_[1]))\n",
    "w3 = np.hstack((clf.intercept_[2], clf.coef_[2]))\n",
    "\n",
    "predict = clf.predict(x_test)\n",
    "\n",
    "Q = sum(predict != y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a3d83-4f2f-404b-a3e7-1264f9c61871",
   "metadata": {},
   "source": [
    "## Задание №5\n",
    "\n",
    "Пусть имеется функция:\n",
    "\n",
    "$f(x) = sin(x/2) + 0.2*cos(2x) - 0.1*sin(4x) + 3 $\n",
    "\n",
    "Требуется выполнить ее аппроксимацию (восстановление) моделью a(x) на интервале [-4; 6]. Модель будем синтезировать (формировать) с помощью метода опорных векторов (для задачи регрессии) с радиальным ядром. \n",
    "\n",
    "Ниже в программе задана функция f(x) с именем func и сформирована обучающая выборка coord_x, coord_y\n",
    "\n",
    "Требуется продолжить программу и сформировать модель a(x), используя объект svr класса SVR:\n",
    "\n",
    "``svr = svm.SVR(kernel='rbf')    # SVM с нелинейным ядром``\n",
    "\n",
    "Выполните обучение модели a(x) путем вызова метода fit объекта svr с передачей каждого третьего отсчета из выборки coord_x, coord_y:\n",
    "\n",
    "``x_train = coord_x[::3]``\n",
    "\n",
    "``y_train = coord_y[::3]``\n",
    "\n",
    "Постройте прогноз обученной моделью a(x) для всей выборки coord_x путем вызова метода predict объекта svr. Результат сохраните в переменной predict.\n",
    "\n",
    "Вычислите качество восстановления исходной функции f(x) обученной моделью a(x) по формуле:\n",
    "\n",
    "$$Q(a,X) = \\frac{1}{n} \\sum_ {i=1}^n (predict_i - y_i)^2 $$\n",
    "\n",
    "Сохраните значение величины Q(a,X) в переменной ``Q``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac53a41f-e7c8-4ed1-90e2-9f34746993f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "def func(x):\n",
    "    return np.sin(0.5*x) + 0.2 * np.cos(2*x) - 0.1 * np.sin(4 * x) + 3\n",
    "\n",
    "# обучающая выборка\n",
    "coord_x = np.expand_dims(np.arange(-4.0, 6.0, 0.1), axis=1)\n",
    "coord_y = func(coord_x).ravel()\n",
    "\n",
    "x_train = coord_x[::3]\n",
    "y_train = coord_y[::3]\n",
    "\n",
    "svr = svm.SVR(kernel='rbf')\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "predict = svr.predict(coord_x)\n",
    "\n",
    "Q = np.mean((predict - coord_y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32c94e-a78b-4efc-9789-f06897c822d6",
   "metadata": {},
   "source": [
    "## Задание №6\n",
    "\n",
    "В программе ниже генерируется обучающая выборка x_train, y_train и тестовая выборка x_test, y_test для двух классов с метками Y={−1,+1}.\n",
    "\n",
    "С помощью объекта clf класса SVC с радиальным ядром:\n",
    "\n",
    "``clf = svm.SVC(kernel='rbf')    # SVM с нелинейным ядром``\n",
    "\n",
    "выполните обучение модели по выборке x_train, y_train путем вызова метода fit объекта clf. Затем, протестируйте обученную модель на тестовой выборке x_test, y_test. Вычислите для нее показатель качества Q(a,X) по следующей формуле:\n",
    "\n",
    "$$Q(a,X) = \\frac{1}{n} \\sum_ {i=1}^n [y_i \\not = a(x_i)] $$\n",
    "\n",
    "Сохраните значение величины Q(a,X) в переменной ``Q``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b11a7a-5e83-40f9-9899-16eab7d78317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
